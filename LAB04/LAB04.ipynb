{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader\n","from torchvision.models import resnet18 as model"],"metadata":{"id":"m6TX4Q8UlI6_","executionInfo":{"status":"ok","timestamp":1677177732348,"user_tz":-330,"elapsed":782,"user":{"displayName":"CE053_Gaurav_Kaklotar","userId":"07042279493659388732"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["inputs = np.array(\n","    [[73, 67, 43],\n","    [91, 88, 64],\n","    [87, 134, 58],\n","    [102, 43, 37],\n","    [69, 96, 70]], \n","  dtype='float32')\n","\n","targets = np.array([[56.],[81.],[119.],[22.],[103.]])"],"metadata":{"id":"pdFuritElJJU","executionInfo":{"status":"ok","timestamp":1677177732853,"user_tz":-330,"elapsed":16,"user":{"displayName":"CE053_Gaurav_Kaklotar","userId":"07042279493659388732"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Ab_1rRTrIeo","executionInfo":{"status":"ok","timestamp":1677177732855,"user_tz":-330,"elapsed":16,"user":{"displayName":"CE053_Gaurav_Kaklotar","userId":"07042279493659388732"}},"outputId":"51af499c-3265-44d6-9134-40574251496b"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-c760f4d3dd29>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  weights=torch.tensor(weights,requires_grad=True)\n","<ipython-input-4-c760f4d3dd29>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  bias=torch.tensor(bias,requires_grad=True)\n"]},{"output_type":"stream","name":"stdout","text":["finalLoss :  0.5140101946832146\n","weights :  tensor([[-0.4154],\n","        [ 0.8482],\n","        [ 0.6743]], grad_fn=<SubBackward0>)\n","bias :  tensor([[1.9665],\n","        [1.9777],\n","        [2.0110],\n","        [2.0035],\n","        [2.0254]], grad_fn=<SubBackward0>)\n"]}],"source":["w=[[1.],[1.],[1.]]\n","b=[[2.],[2.],[2.],[2.],[2.]]\n","\n","learningRate=0.0001\n","iterations=1000\n","\n","m=len(inputs)*1.0\n","\n","weights=torch.tensor(w, requires_grad=True)\n","bias=torch.tensor(b, requires_grad=True)\n","\n","\n","finalLoss=0.0\n","\n","for _ in range(iterations):\n","  weights=torch.tensor(weights,requires_grad=True)\n","  bias=torch.tensor(bias,requires_grad=True)\n","\n","  inputs1=torch.tensor(inputs,requires_grad=False)\n","  y1=torch.tensor(targets)\n","  \n","  hypo=torch.matmul(inputs1,weights)+bias\n","  loss=((hypo-y1)**2)\n","  \n","  myloss=0.0\n","\n","  for row in loss:\n","    myloss+=row[0]\n","  myloss/=2*m\n","  myloss.backward()\n","  # print(\"myloss : \",myloss)\n","  \n","  weights=weights-((weights.grad)*learningRate)\n","  bias=bias-((bias.grad)*learningRate)\n","\n","  finalLoss=myloss.item()\n","print(\"finalLoss : \",finalLoss)\n","print(\"weights : \",weights)\n","print(\"bias : \",bias)\n"]}]}